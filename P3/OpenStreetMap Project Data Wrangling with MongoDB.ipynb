{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap Project Data Wrangling with MongoDB\n",
    "###### Yuki Steineman\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About map data\n",
    "\n",
    "- Area: south lake tahoe, california \n",
    "- Download Link: https://mapzen.com/data/metro-extracts/\n",
    "- Size: 120.2MB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "- Input file: south-lake-tahoe_california.osm (120MB)\n",
    "- Output file: south-lake-tahoe_california.osm.json (25MB)\n",
    "\n",
    "Features\n",
    "\n",
    "1. Standarize street name (St -> Street etc).\n",
    "2. Exclude k attribute which contains symbols by regex.\n",
    "3. Output k attribute as \"point_info\".\n",
    "4. Exclude some k attribute which seems not informational, such as created_by, source, and highway.\n",
    "\n",
    "Stuck on running mongoDB\n",
    "\n",
    "- db.tahoe.insert_many(data) function returned \"ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused\"\n",
    "- I already installed pymongo, but haven't installed mongodb itself. I referred this instruction.  (https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/)\n",
    "- To install mongodb, I used virtualenv and virtualenvwrapper. (http://docs.python-guide.org/en/latest/dev/virtualenvs/)\n",
    "```\n",
    "Start work on env: \n",
    "$ source /usr/local/bin/virtualenvwrapper.sh\n",
    "$ workon something\n",
    "Finish:\n",
    "$ deactivate\n",
    "```        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "# regex\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "EXCLUDE = [\"created_by\", \"source\" , \"highway\", \"import_uuid\", \"ele\", \"is_in\", \"attribution\", \"ref\", \"exit_to\"]\n",
    "STREET = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# Street mapping\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"DR\": \"Drive\",\n",
    "            \"CT\": \"Court\",\n",
    "            \"PL\": \"Place\",\n",
    "            \"SQ\": \"Square\",\n",
    "            \"LN\": \"Lane\",\n",
    "            \"TRL\": \"Trail\",\n",
    "            \"PKWY\": \"Parkway\",\n",
    "            \"CMNS\": \"Commons\"\n",
    "          }\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        fo.write(\"[\")\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\",\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \",\\n\")\n",
    "        fo.write(\"]\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created': {'changeset': '12599511',\n",
      "             'timestamp': '2012-08-03T15:23:02Z',\n",
      "             'uid': '169004',\n",
      "             'user': 'oldtopos',\n",
      "             'version': '3'},\n",
      " 'id': '26798725',\n",
      " 'pos': [39.4433397, -120.0117505],\n",
      " 'type': 'node'}\n"
     ]
    }
   ],
   "source": [
    "def shape_element(element):\n",
    "    node = {}\n",
    "    address = {}\n",
    "    node_refs = []\n",
    "    info = {}\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        created = {}\n",
    "        pos = [None, None]\n",
    "        for attr in element.attrib.keys():\n",
    "            if attr == 'id':\n",
    "                node[\"id\"] = element.attrib[attr]\n",
    "            if attr == \"visible\":\n",
    "                node[\"visible\"] = element.attrib[attr]\n",
    "            if attr in CREATED:\n",
    "                created[attr] = element.attrib[attr]\n",
    "            # pos\n",
    "            if attr == 'lat':\n",
    "                pos[0] = float(element.attrib[attr])\n",
    "            if attr == 'lon':\n",
    "                pos[1] = float(element.attrib[attr])\n",
    "                \n",
    "        node[\"type\"] = element.tag\n",
    "        node[\"created\"] = created\n",
    "        if pos[0]:\n",
    "            node[\"pos\"] = pos\n",
    "       \n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.attrib['k']\n",
    "            # address standarize\n",
    "            if k.startswith(\"addr:\"):\n",
    "                if lower_colon.search(k):\n",
    "                    v = tag.attrib['v']\n",
    "                    matcher = street_type_re.search(v)\n",
    "                    if matcher:\n",
    "                        streetname = matcher.group(0) \n",
    "                        if streetname in mapping:\n",
    "                            # set standarized street name\n",
    "                            address[k[5:]] = v.replace(streetname, mapping[streetname])\n",
    "                        else:\n",
    "                            address[k[5:]] = v\n",
    "                    else:\n",
    "                        address[k[5:]] = v\n",
    "                    \n",
    "            # not address\n",
    "            elif lower.search(k):\n",
    "                # exclude unnecessary tag defined in 'EXCLUDE'\n",
    "                if not k in EXCLUDE:\n",
    "                    info[k] = tag.attrib['v']\n",
    "                    \n",
    "            # contains symbols\n",
    "            elif problemchars.search(k):\n",
    "                pass\n",
    "\n",
    "        if address:\n",
    "            node[\"address\"] = address\n",
    "        if info:\n",
    "            node[\"point_info\"] = info \n",
    "            \n",
    "        # node_refs\n",
    "        for tag in element.iter('nd'):\n",
    "            ref = tag.attrib['ref']\n",
    "            node_refs.append(ref)\n",
    "            \n",
    "        if node_refs:\n",
    "            node[\"node_refs\"] = node_refs\n",
    "            \n",
    "        return node\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = process_map('south-lake-tahoe_california.osm', True)\n",
    "    #data = process_map('test.osm', True)\n",
    "    pprint.pprint(data[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'laketahoe')\n"
     ]
    }
   ],
   "source": [
    "def get_db():\n",
    "    # For local use\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    # 'examples' here is the database name. It will be created if it does not exist.\n",
    "    db = client.laketahoe\n",
    "    return db\n",
    "\n",
    "db = get_db()\n",
    "print db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read osm (json format) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'created': {u'changeset': u'12599511',\n",
      "              u'timestamp': u'2012-08-03T15:23:02Z',\n",
      "              u'uid': u'169004',\n",
      "              u'user': u'oldtopos',\n",
      "              u'version': u'3'},\n",
      " u'id': u'26798725',\n",
      " u'pos': [39.4433397, -120.0117505],\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"south-lake-tahoe_california.osm.json\", \"r\") as fi:\n",
    "# remove comma\n",
    "    data = json.load(fi)\n",
    "pprint.pprint(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insert to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x10501ff00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.tahoe.insert_many(data)\n",
    "# not insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5732cf73ce0450d2cf2dfe00'),\n",
       " u'created': {u'changeset': u'12599511',\n",
       "  u'timestamp': u'2012-08-03T15:23:02Z',\n",
       "  u'uid': u'169004',\n",
       "  u'user': u'oldtopos',\n",
       "  u'version': u'3'},\n",
       " u'id': u'26798725',\n",
       " u'pos': [39.4433397, -120.0117505],\n",
       " u'type': u'node'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.tahoe.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of contribution\n",
    "\n",
    "Total 98,847 posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 724873\n"
     ]
    }
   ],
   "source": [
    "tcount = db.tahoe.find({\"created.user\": { \"$ne\": None }}).count() \n",
    "print 'Number of posts:', tcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User contribution ranking\n",
    "Most posted user is 'woodpeck_fixbot', 17% of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'User: woodpeck_fixbot, Count: 127156, Ratio: 17.0'\n",
      "'User: nmixter, Count: 103801, Ratio: 14.0'\n",
      "'User: theangrytomato, Count: 82896, Ratio: 11.0'\n",
      "'User: AndrewBuck, Count: 66328, Ratio: 9.0'\n",
      "'User: MelanieOriet, Count: 26138, Ratio: 3.0'\n",
      "'User: lucaswoj, Count: 22137, Ratio: 3.0'\n",
      "'User: paulmach, Count: 21365, Ratio: 2.0'\n",
      "'User: abschiff, Count: 15213, Ratio: 2.0'\n",
      "'User: wallclimber21, Count: 14867, Ratio: 2.0'\n",
      "'User: Marshy8, Count: 14016, Ratio: 1.0'\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "         { \"$match\": {\"created.user\": { \"$ne\": None }}}, \n",
    "         {\"$group\": {\"_id\" : \"$created.user\", \"count\" : {\"$sum\": 1} }},\n",
    "         {\"$sort\" : { \"count\" : -1 } },\n",
    "         {\"$limit\" : 10 }]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tahoe.aggregate(pipeline)]\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "\n",
    "for r in result:\n",
    "    r['ratio'] = math.floor((float(r['count']) / float(tcount)) * 100)\n",
    "    print 'User: {0}, Count: {1}, Ratio: {2}'.format(r['_id'], r['count'], r['ratio'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most contributed year \n",
    "\n",
    "- 2012: 25% (of the total)\n",
    "- 2009: 23%\n",
    "- 2015: 15%\n",
    "- 2014: 15%\n",
    "- 2013: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2012, Count: 182291, Ratio: 25.0\n",
      "Year: 2009, Count: 167322, Ratio: 23.0\n",
      "Year: 2015, Count: 112548, Ratio: 15.0\n",
      "Year: 2014, Count: 110582, Ratio: 15.0\n",
      "Year: 2013, Count: 79033, Ratio: 10.0\n",
      "Year: 2016, Count: 26409, Ratio: 3.0\n",
      "Year: 2010, Count: 20176, Ratio: 2.0\n",
      "Year: 2011, Count: 19110, Ratio: 2.0\n",
      "Year: 2008, Count: 5811, Ratio: 0.0\n",
      "Year: 2007, Count: 1591, Ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "         { \"$match\": {\"created.timestamp\": { \"$ne\": None }}}, \n",
    "         {\"$group\": {\"_id\" : {\"$substr\": [ \"$created.timestamp\", 0, 4 ]}, \"count\" : {\"$sum\": 1} }},\n",
    "         {\"$sort\" : { \"count\" : -1 } }\n",
    "        ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tahoe.aggregate(pipeline)]\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "\n",
    "for r in result:\n",
    "    r['ratio'] = math.floor((float(r['count']) / float(tcount)) * 100)\n",
    "    print 'Year: {0}, Count: {1}, Ratio: {2}'.format(r['_id'],r['count'],r['ratio'])\n",
    "#pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detail of contribution by user and year\n",
    "- User 'woodpeck_fixbot' contributed most but only active in 2009.\n",
    "- Two users 'nmixter' and 'AndrewBuck' were active in 2012.\n",
    "- User 'theangrytomato' was active in 2014 and 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: woodpeck_fixbot, Year: 2009, Count: 127156, Ratio: 17.0\n",
      "User: nmixter, Year: 2012, Count: 86458, Ratio: 11.0\n",
      "User: AndrewBuck, Year: 2012, Count: 51902, Ratio: 7.0\n",
      "User: theangrytomato, Year: 2015, Count: 41349, Ratio: 5.0\n",
      "User: theangrytomato, Year: 2014, Count: 30271, Ratio: 4.0\n",
      "User: lucaswoj, Year: 2014, Count: 22136, Ratio: 3.0\n",
      "User: MelanieOriet, Year: 2013, Count: 20406, Ratio: 2.0\n",
      "User: AndrewBuck, Year: 2013, Count: 14426, Ratio: 1.0\n",
      "User: Eureka gold, Year: 2012, Count: 12762, Ratio: 1.0\n",
      "User: paulmach, Year: 2015, Count: 11951, Ratio: 1.0\n",
      "User: abschiff, Year: 2009, Count: 11128, Ratio: 1.0\n",
      "User: Marshy8, Year: 2015, Count: 10229, Ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "         { \"$match\": {\"created.user\": { \"$ne\": None }}}, \n",
    "         { \"$match\": {\"created.timestamp\": { \"$ne\": None }}}, \n",
    "         {\"$group\": {\"_id\" : {\"user\":\"$created.user\", \"year\":{\"$substr\": [ \"$created.timestamp\", 0, 4 ]}}, \"count\" : {\"$sum\": 1} }},\n",
    "         {\"$match\": {\"count\": { \"$gt\": 10000 }}},\n",
    "         {\"$sort\" : { \"count\" : -1} }\n",
    "        ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tahoe.aggregate(pipeline)]\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "\n",
    "for r in result:\n",
    "    r['ratio'] = math.floor((float(r['count']) / float(tcount)) * 100)\n",
    "    print 'User: {0}, Year: {1}, Count: {2}, Ratio: {3}'.format(r['_id']['user'],r['_id']['year'],r['count'],r['ratio'])\n",
    "#pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detail of amenity\n",
    "Parking is the most common amenity. Next is school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenity: parking, Count: 371\n",
      "Amenity: school, Count: 158\n",
      "Amenity: post_office, Count: 79\n",
      "Amenity: toilets, Count: 79\n",
      "Amenity: restaurant, Count: 65\n",
      "Amenity: grave_yard, Count: 27\n",
      "Amenity: fast_food, Count: 26\n",
      "Amenity: hospital, Count: 25\n",
      "Amenity: place_of_worship, Count: 22\n",
      "Amenity: cafe, Count: 21\n",
      "Amenity: fuel, Count: 19\n",
      "Amenity: bank, Count: 14\n",
      "Amenity: drinking_water, Count: 14\n",
      "Amenity: fire_station, Count: 12\n",
      "Amenity: pharmacy, Count: 10\n"
     ]
    }
   ],
   "source": [
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "         {\"$match\": {\"point_info.amenity\": { \"$ne\": None }}}, \n",
    "         {\"$unwind\": \"$point_info\"},\n",
    "         {\"$group\": {\"_id\" : \"$point_info.amenity\", \"count\" : {\"$sum\": 1} }},\n",
    "         {\"$sort\" : { \"count\" : -1 } },\n",
    "         {\"$limit\" : 15 }\n",
    "        ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tahoe.aggregate(pipeline)]\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "\n",
    "for r in result:\n",
    "    print 'Amenity: {0}, Count: {1}'.format(r['_id'],r['count'])\n",
    "# pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the most eaten in Lake Tahoe\n",
    "```\n",
    "1. Burger\n",
    "2. Mexican\n",
    "3. Pizza\n",
    "3. American\n",
    "3. Sandwich\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuisine: burger, Count: 8\n",
      "Cuisine: mexican, Count: 7\n",
      "Cuisine: pizza, Count: 5\n",
      "Cuisine: american, Count: 5\n",
      "Cuisine: sandwich, Count: 5\n",
      "Cuisine: coffee_shop, Count: 4\n",
      "Cuisine: chicken, Count: 3\n",
      "Cuisine: thai, Count: 3\n",
      "Cuisine: sushi, Count: 2\n",
      "Cuisine: italian, Count: 2\n",
      "Cuisine: regional, Count: 2\n",
      "Cuisine: german, Count: 1\n",
      "Cuisine: Hawaiian, Count: 1\n",
      "Cuisine: chinese, Count: 1\n",
      "Cuisine: asian, Count: 1\n"
     ]
    }
   ],
   "source": [
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "         {\"$match\": {\"point_info.cuisine\": { \"$ne\": None }}}, \n",
    "         {\"$unwind\": \"$point_info\"},\n",
    "         {\"$group\": {\"_id\" : \"$point_info.cuisine\", \"count\" : {\"$sum\": 1} }},\n",
    "         {\"$sort\" : { \"count\" : -1 } }\n",
    "        ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tahoe.aggregate(pipeline)]\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "\n",
    "for r in result:\n",
    "    print 'Cuisine: {0}, Count: {1}'.format(r['_id'],r['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some trick I learned from above\n",
    "\n",
    "- Substring; pick up year from timestamp\n",
    "```\n",
    "\"year\":{\"$substr\": [ \"$created.timestamp\", 0, 4 ]}}\n",
    "```\n",
    "\n",
    "- Group with Nested element\n",
    "```\n",
    " {\"$unwind\": \"$point_info\"},\n",
    " {\"$group\": {\"_id\" : \"$point_info.amenity\", \"count\" : {\"$sum\": 1} }}\n",
    "```\n",
    "\n",
    "- Multiple sort key\n",
    "```\n",
    "{\"$sort\" : { \"year\" : -1, \"count\" : -1} }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In \"Detail of contribution by user and year\" section, I planned to get the most contributed user in each year. But I couldn't figure out the way to sort and limit in each year.  \n",
    "MongoDB is still not handy for me, however, we don't need to transform json format to save in database, this feature is quite attractive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
