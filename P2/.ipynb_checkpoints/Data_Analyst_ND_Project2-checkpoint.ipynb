{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the NYC Subway Dataset\n",
    "## Questions\n",
    "## Overview\n",
    "This project consists of two parts. In Part 1 of the project, you should have completed the questions in Problem Sets 2, 3, and 4 in the Introduction to Data Science course.\n",
    "This document addresses part 2 of the project. Please use this document as a template and answer the following questions to explain your reasoning and conclusion behind your work in the problem sets. You will attach a document with your answers to these questions as part of your final project submission.\n",
    "Section 0. References\n",
    "\n",
    "Please include a list of references you have used for this project. Please be specific - for example, instead of including a general website such as stackoverflow.com, try to include a specific topic from Stackoverflow that you have found useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0. References\n",
    "- [scipy.stats.mannwhitneyu](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n",
    "- [Mann-Whitney U Test using SPSS](https://statistics.laerd.com/spss-tutorials/mann-whitney-u-test-using-spss-statistics.php)\n",
    "- [histograms with matplotlib.pyplot](http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "- [numpy.mean](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html)\n",
    "- [R squared](http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)\n",
    "- [Prediction](http://www.unc.edu/~swlt/statawalk4.pdf)\n",
    "- [ggplot](http://blog.yhathq.com/posts/ggplot-for-python.html)\n",
    "- [Normal Distributions](http://www2.nau.edu/mat114-c/ch2a.php)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DESCn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>maxpressurei</th>\n",
       "      <th>maxdewpti</th>\n",
       "      <th>...</th>\n",
       "      <th>meandewpti</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>meanwindspdi</th>\n",
       "      <th>mintempi</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>maxtempi</th>\n",
       "      <th>precipi</th>\n",
       "      <th>thunder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>217</td>\n",
       "      <td>553</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>890</td>\n",
       "      <td>1262</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>2451</td>\n",
       "      <td>3708</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>4400</td>\n",
       "      <td>2501</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  UNIT       DATEn     TIMEn  Hour    DESCn  ENTRIESn_hourly  \\\n",
       "0           0  R001  2011-05-01  01:00:00     1  REGULAR                0   \n",
       "1           1  R001  2011-05-01  05:00:00     5  REGULAR              217   \n",
       "2           2  R001  2011-05-01  09:00:00     9  REGULAR              890   \n",
       "3           3  R001  2011-05-01  13:00:00    13  REGULAR             2451   \n",
       "4           4  R001  2011-05-01  17:00:00    17  REGULAR             4400   \n",
       "\n",
       "   EXITSn_hourly  maxpressurei  maxdewpti   ...     meandewpti  meanpressurei  \\\n",
       "0              0         30.31         42   ...             39          30.27   \n",
       "1            553         30.31         42   ...             39          30.27   \n",
       "2           1262         30.31         42   ...             39          30.27   \n",
       "3           3708         30.31         42   ...             39          30.27   \n",
       "4           2501         30.31         42   ...             39          30.27   \n",
       "\n",
       "   fog  rain  meanwindspdi  mintempi  meantempi  maxtempi  precipi  thunder  \n",
       "0    0     0             5        50         60        69        0        0  \n",
       "1    0     0             5        50         60        69        0        0  \n",
       "2    0     0             5        50         60        69        0        0  \n",
       "3    0     0             5        50         60        69        0        0  \n",
       "4    0     0             5        50         60        69        0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "filename = 'turnstile_data_master_with_weather.csv'\n",
    "\n",
    "dataFrame = pandas.read_csv(filename)\n",
    "dataFrame.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Statistical Test\n",
    " \n",
    "### 1.1 Which statistical test did you use to analyze the NYC subway data? Did you use a one-tail or a two-tail P value? What is the null hypothesis? What is your p-critical value?\n",
    "\n",
    "I used Mann-Whitney U-Test, and two-tail P value. The null hypothesis is that there is no difference between the means of the two samples. My p-critical value is 0.05.\n",
    "\n",
    "References:\n",
    "[Mann-Whitney U](http://www.statisticslectures.com/topics/mannwhitneyu/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Why is this statistical test applicable to the dataset? In particular, consider the assumptions that the test is making about the distribution of ridership in the two samples.\n",
    "\n",
    "Why Mann-Whitney U-Test should be used?\n",
    "\n",
    "A.\n",
    "- My dependent variable is the number of the people who enter the station ('ENTRIESn_hourly'), which is an ordinal variable. \n",
    "- My independent variable is 'rainy day' and 'non-rainy day', which are categorical independent groups. Riders are not the exactly same on rainy day and non-rainy day.\n",
    "- The two samples with rainy days and non-rainy days, are not normally distributed, however, they have the same shape accourding to the histogram with pyplot.\n",
    "\n",
    "References:\n",
    "[Mann-Whitney U Test using SPSS](https://statistics.laerd.com/spss-tutorials/mann-whitney-u-test-using-spss-statistics.php)\n",
    "\n",
    ">Assumption #1: Your dependent variable should be measured at the ordinal or continuous level. Examples of ordinal variables include Likert items (e.g., a 7-point scale from \"strongly agree\" through to \"strongly disagree\"), amongst other ways of ranking categories (e.g., a 5-point scale explaining how much a customer liked a product, ranging from \"Not very much\" to \"Yes, a lot\"). Examples of continuous variables include revision time (measured in hours), intelligence (measured using IQ score), exam performance (measured from 0 to 100), weight (measured in kg), and so forth. You can learn more about ordinal and continuous variables in our article: Types of Variable.\n",
    "\n",
    ">Assumption #2: Your independent variable should consist of two categorical, independent groups. Example independent variables that meet this criterion include gender (2 groups: male or female), employment status (2 groups: employed or unemployed), smoker (2 groups: yes or no), and so forth.\n",
    "\n",
    ">Assumption #3: You should have independence of observations, which means that there is no relationship between the observations in each group or between the groups themselves. For example, there must be different participants in each group with no participant being in more than one group. This is more of a study design issue than something you can test for, but it is an important assumption of the Mann-Whitney U test. If your study fails this assumption, you will need to use another statistical test instead of the Mann-Whitney U test (e.g., a Wilcoxon signed-rank test). If you are unsure whether your study meets this assumption, you can use our Statistical Test Selector, which is part of our enhanced content.\n",
    "\n",
    ">Assumption #4: A Mann-Whitney U test can be used when your two variables are not normally distributed. However, in order to know how to interpret the results from a Mann-Whitney U test, you have to determine whether your two distributions (i.e., the distribution of scores for both groups of the independent variable; for example, 'males' and 'females' for the independent variable, 'gender') have the same shape. To understand what this means, take a look at the diagram below:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\Users\\Yukiko\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.pyc'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def entries_histogram(turnstile_weather): \n",
    "    fig = plt.figure()\n",
    "    turnstile_weather['ENTRIESn_hourly'][(turnstile_weather['rain'] == 0) & \n",
    "                                         (turnstile_weather['ENTRIESn_hourly'] < 6000)].hist(bins=20, label='Rainy Day')\n",
    "                                                                                            \n",
    "    turnstile_weather['ENTRIESn_hourly'][(turnstile_weather['rain'] == 1) & \n",
    "                                         (turnstile_weather['ENTRIESn_hourly'] < 6000)].hist(bins=20, label='Non-Rainy Day')\n",
    "    plt.legend()\n",
    "    ax = fig.add_subplot(111)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    ax.set_title('The number of users of the station by rainy day and non-rainy day')\n",
    "\n",
    "    ax.set_xlabel('Hourly Users')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "entries_histogram(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 What results did you get from this statistical test? These should include the following numerical values: p-values, as well as the means for each of the two samples under test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.\n",
      "Mean of the rainy day sample: 1105.44637675\n",
      "Mean of the non-rainy day sample: 1090.27878015\n",
      "U-value: 1924409167.0\n",
      "P-value: 0.0193096344138\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def mann_whitney_plus_means(turnstile_weather):\n",
    "\n",
    "    wr = turnstile_weather['ENTRIESn_hourly'][(turnstile_weather['rain'] == 1)]\n",
    "    wor = turnstile_weather['ENTRIESn_hourly'][(turnstile_weather['rain'] == 0)]\n",
    "    with_rain_mean = np.mean(wr)\n",
    "    without_rain_mean = np.mean(wor)\n",
    "    U, p = scipy.stats.mannwhitneyu(wr,wor)\n",
    "    return with_rain_mean, without_rain_mean, U, p\n",
    "\n",
    "with_rain_mean, without_rain_mean, U, p = mann_whitney_plus_means(dataFrame)\n",
    "\n",
    "print 'A.'\n",
    "print 'Mean of the rainy day sample:', with_rain_mean\n",
    "print 'Mean of the non-rainy day sample:', without_rain_mean\n",
    "print 'U-value:', U\n",
    "print 'P-value:', p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 What is the significance and interpretation of these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "\n",
    "My confidence level is 95% and critical statistic value (α) is 0.05.\n",
    "P-value is 0.019 and \"P:0.019 < 0.025\" is true, so it's rejecting the null hypothesis. There is a significant difference between the means of the two samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What approach did you use to compute the coefficients theta and produce prediction for ENTRIESn_hourly in your regression model: OLS using Statsmodels or Scikit Learn Gradient descent using Scikit Learn Or something different?\n",
    "\n",
    "A.\n",
    "\n",
    "My approach is OLS using Statsmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 What features (input variables) did you use in your model? Did you use any dummy variables as part of your features?\n",
    "\n",
    "- Features:       'Hour', 'rain', 'meantempi', 'meanwindspdi'\n",
    "- Dummy variable: 'UNIT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Why did you select these features in your model? We are looking for specific reasons that lead you to believe that\n",
    ">the selected features will contribute to the predictive power of your model.\n",
    "Your reasons might be based on intuition. For example, response for fog might be: “I decided to use fog because I thought that when it is very foggy outside people might decide to use the subway more often.”\n",
    "Your reasons might also be based on data exploration and experimentation, for example: “I used feature X because as soon as I included it in my model, it drastically improved my R2 value.”  \n",
    "\n",
    "A.\n",
    "- Hour: More people may use the subway in the morning and evening time and less around noon and midnight.\n",
    "- Precipitation('precipi'): People may decide to use the subway depending on how hard it rains. \n",
    "- Mean of temperature('meantempi'): People may use the subway when it's hot or cold.\n",
    "- Mean of strength of wing('meanwindspdi'): People may use the subway instead of bycicles when there's strong wind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 What are the parameters (also known as \"coefficients\" or \"weights\") of the non-dummy features in your linear regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "\n",
    "The parameters: 'Hour', 'rain', 'meantempi', 'meanwindspdi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 What is your model’s R2 (coefficients of determination) value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1033.47906555\n",
      "Parameters:\n",
      "Hour              67.400584\n",
      "rain               1.054923\n",
      "meantempi         -4.898364\n",
      "meanwindspdi      24.205276\n",
      "unit_R001       2429.030590\n",
      "unit_R002       -634.209030\n",
      "unit_R003      -1331.095823\n",
      "unit_R004      -1008.449823\n",
      "unit_R005      -1019.946764\n",
      "unit_R006       -949.605907\n",
      "unit_R007      -1169.498301\n",
      "unit_R008      -1135.879957\n",
      "unit_R009      -1205.884714\n",
      "unit_R010       3030.596694\n",
      "unit_R011       6515.030796\n",
      "unit_R012       5951.318149\n",
      "unit_R013        965.135018\n",
      "unit_R014       2486.420786\n",
      "unit_R015        625.556082\n",
      "unit_R016       -566.937811\n",
      "unit_R017       2709.520105\n",
      "unit_R018       4420.983949\n",
      "unit_R019       1379.442979\n",
      "unit_R020       4976.241530\n",
      "unit_R021       2950.195688\n",
      "unit_R022       7107.278487\n",
      "unit_R023       5024.033880\n",
      "unit_R024       1507.268836\n",
      "unit_R025       3514.971025\n",
      "unit_R027       1432.699432\n",
      "                   ...     \n",
      "unit_R450      -1033.977692\n",
      "unit_R451       -607.231002\n",
      "unit_R452       4215.142517\n",
      "unit_R453        311.691623\n",
      "unit_R454      -1344.667076\n",
      "unit_R455      -1395.149664\n",
      "unit_R456      -1265.377292\n",
      "unit_R459      -1428.059583\n",
      "unit_R460         16.441536\n",
      "unit_R461       1565.544416\n",
      "unit_R462        498.059487\n",
      "unit_R463       1580.660254\n",
      "unit_R464      -1540.403594\n",
      "unit_R468      -1078.364861\n",
      "unit_R469      -1075.619305\n",
      "unit_R535      -1084.557687\n",
      "unit_R536      -1074.109157\n",
      "unit_R540      -1368.609531\n",
      "unit_R541      -1475.121732\n",
      "unit_R542      -1494.964437\n",
      "unit_R543      -1531.856780\n",
      "unit_R544      -1545.082413\n",
      "unit_R545      -1495.566608\n",
      "unit_R546      -1356.915211\n",
      "unit_R547      -1464.188733\n",
      "unit_R548      -1428.322316\n",
      "unit_R549      -1568.854018\n",
      "unit_R550      -1530.896951\n",
      "unit_R551      -1503.389690\n",
      "unit_R552      -1439.254109\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def linear_regression(features, values):\n",
    "\n",
    "    features = sm.add_constant(features)\n",
    "    model = sm.OLS(values, features)\n",
    "    results = model.fit()\n",
    "    params = results.params\n",
    "    intercept = results.params[0]\n",
    "    params = results.params[1:]\n",
    "    \n",
    "    return intercept, params\n",
    "\n",
    "def predictions(dataframe):\n",
    "    features = dataframe[['Hour', 'rain', 'meantempi', 'meanwindspdi']]\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "\n",
    "    # Perform linear regression\n",
    "    intercept, params = linear_regression(features, values)\n",
    "    print 'Intercept:' ,intercept\n",
    "    print 'Parameters:'\n",
    "    print params\n",
    "      \n",
    "    predictions = intercept + np.dot(features, params)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "mta_predictions = predictions(dataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_value: 0.458366819436\n"
     ]
    }
   ],
   "source": [
    "import operator as op\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "\n",
    "    SST = ((data - np.mean(data))**2).sum()\n",
    "    SSReg = ((predictions - data)**2).sum()\n",
    "    r_squared = 1 - SSReg / SST\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "r2_value = compute_r_squared(dataFrame['ENTRIESn_hourly'], mta_predictions)\n",
    "print 'R2_value:', r2_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 What does this R2 value mean for the goodness of fit for your regression model? Do you think this linear model to predict ridership is appropriate for this dataset, given this R2  value?\n",
    "A.\n",
    "\n",
    "The R2_value, 0.46(46%) indicates that the model explains within half of the variability of the ridership data around the mean.\n",
    "\n",
    "References:\n",
    "- [R squared](http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)\n",
    "- [Prediction](http://www.unc.edu/~swlt/statawalk4.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Visualization\n",
    "\n",
    "Please include two visualizations that show the relationships between two or more variables in the NYC subway data.\n",
    "Remember to add appropriate titles and axes labels to your plots. Also, please add a short description below each figure commenting on the key insights depicted in the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 One visualization should contain two histograms: one of  ENTRIESn_hourly for rainy days and one of ENTRIESn_hourly for non-rainy days.\n",
    "You can combine the two histograms in a single plot or you can use two separate plots.\n",
    "If you decide to use to two separate plots for the two histograms, please ensure that the x-axis limits for both of the plots are identical. It is much easier to compare the two in that case.\n",
    "For the histograms, you should have intervals representing the volume of ridership (value of ENTRIESn_hourly) on the x-axis and the frequency of occurrence on the y-axis. For example, each interval (along the x-axis), the height of the bar for this interval will represent the number of records (rows in our data) that have ENTRIESn_hourly that falls in this interval.\n",
    "Remember to increase the number of bins in the histogram (by having larger number of bars). The default bin width is not sufficient to capture the variability in the two samples.\n",
    "\n",
    "References:\n",
    "- [ggplot](https://pypi.python.org/pypi/ggplot/)\n",
    "- [Axis limit](http://docs.ggplot2.org/0.9.3/xylim.html)\n",
    "- [geom_histogram](http://ggplot.yhathq.com/docs/geom_histogram.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert value of 'rain' from 0 or 1 to the text for legends. \n",
    "dataFrame['rain'] = dataFrame['rain'].apply(lambda x: 'Rainy Day' if x == 1 else 'Non-Rainy Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0           Hour  ENTRIESn_hourly  EXITSn_hourly  \\\n",
      "count  131951.000000  131951.000000    131951.000000  131951.000000   \n",
      "mean    65975.000000      10.896158      1095.348478     886.890838   \n",
      "std     38091.117022       6.892084      2337.015421    2008.604886   \n",
      "min         0.000000       0.000000         0.000000       0.000000   \n",
      "25%     32987.500000       5.000000        39.000000      32.000000   \n",
      "50%     65975.000000      12.000000       279.000000     232.000000   \n",
      "75%     98962.500000      17.000000      1109.000000     847.000000   \n",
      "max    131950.000000      23.000000     51839.000000   45249.000000   \n",
      "\n",
      "        maxpressurei      maxdewpti      mindewpti   minpressurei  \\\n",
      "count  131951.000000  131951.000000  131951.000000  131951.000000   \n",
      "mean       30.031894      57.241302      48.259013      29.892714   \n",
      "std         0.125689       8.770891      11.305312       0.146384   \n",
      "min        29.740000      39.000000      22.000000      29.540000   \n",
      "25%        29.960000      50.000000      38.000000      29.840000   \n",
      "50%        30.030000      57.000000      51.000000      29.910000   \n",
      "75%        30.100000      64.000000      55.000000      29.970000   \n",
      "max        30.310000      70.000000      66.000000      30.230000   \n",
      "\n",
      "          meandewpti  meanpressurei            fog   meanwindspdi  \\\n",
      "count  131951.000000  131951.000000  131951.000000  131951.000000   \n",
      "mean       52.703526      29.965077       0.167100       5.543065   \n",
      "std         9.943590       0.130461       0.373066       1.982441   \n",
      "min        31.000000      29.640000       0.000000       1.000000   \n",
      "25%        45.000000      29.910000       0.000000       5.000000   \n",
      "50%        54.000000      29.960000       0.000000       5.000000   \n",
      "75%        60.000000      30.050000       0.000000       6.000000   \n",
      "max        68.000000      30.270000       1.000000      12.000000   \n",
      "\n",
      "            mintempi      meantempi       maxtempi        precipi  thunder  \n",
      "count  131951.000000  131951.000000  131951.000000  131951.000000   131951  \n",
      "mean       56.169775      64.269729      71.769968       0.172276        0  \n",
      "std         6.338875       6.568289       7.627218       0.429005        0  \n",
      "min        46.000000      55.000000      58.000000       0.000000        0  \n",
      "25%        52.000000      60.000000      65.000000       0.000000        0  \n",
      "50%        54.000000      63.000000      71.000000       0.000000        0  \n",
      "75%        60.000000      68.000000      78.000000       0.100000        0  \n",
      "max        70.000000      78.000000      86.000000       2.180000        0  \n"
     ]
    }
   ],
   "source": [
    "print dataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ggplot: (92012965)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ggplot import *\n",
    "pandas.options.mode.chained_assignment = None\n",
    "\n",
    "def plot_weather_data(turnstile_weather):\n",
    "    \n",
    "    plot = ggplot(turnstile_weather, aes('ENTRIESn_hourly', fill='rain')) + \\\n",
    "    geom_histogram(binwidth=100) + \\\n",
    "    xlim(0, 5000) + \\\n",
    "    ylab('Frequency') + xlab('Number of Hourly Users') + ggtitle('Number of Hourly Users by Rain')\n",
    "\n",
    "    return plot\n",
    "\n",
    "plot_weather_data(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 One visualization can be more freeform. You should feel free to implement something that we discussed in class (e.g., scatter plots, line plots) or attempt to implement something more advanced if you'd like. Some suggestions are: Ridership by time-of-day, Ridership by day-of-week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import \"Improved data set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UNIT     DATEn     TIMEn  ENTRIESn   EXITSn  ENTRIESn_hourly  \\\n",
      "0  R003  05-01-11  00:00:00   4388333  2911002                0   \n",
      "1  R003  05-01-11  04:00:00   4388333  2911002                0   \n",
      "2  R003  05-01-11  12:00:00   4388333  2911002                0   \n",
      "3  R003  05-01-11  16:00:00   4388333  2911002                0   \n",
      "4  R003  05-01-11  20:00:00   4388333  2911002                0   \n",
      "\n",
      "   EXITSn_hourly             datetime  hour  day_week     ...       pressurei  \\\n",
      "0              0  2011-05-01 00:00:00     0         6     ...           30.22   \n",
      "1              0  2011-05-01 04:00:00     4         6     ...           30.25   \n",
      "2              0  2011-05-01 12:00:00    12         6     ...           30.28   \n",
      "3              0  2011-05-01 16:00:00    16         6     ...           30.26   \n",
      "4              0  2011-05-01 20:00:00    20         6     ...           30.28   \n",
      "\n",
      "  rain  tempi  wspdi meanprecipi  meanpressurei  meantempi  meanwspdi  \\\n",
      "0    0   55.9    3.5           0         30.258      55.98       7.86   \n",
      "1    0   52.0    3.5           0         30.258      55.98       7.86   \n",
      "2    0   62.1    6.9           0         30.258      55.98       7.86   \n",
      "3    0   57.9   15.0           0         30.258      55.98       7.86   \n",
      "4    0   52.0   10.4           0         30.258      55.98       7.86   \n",
      "\n",
      "   weather_lat  weather_lon  \n",
      "0    40.700348   -73.887177  \n",
      "1    40.700348   -73.887177  \n",
      "2    40.700348   -73.887177  \n",
      "3    40.700348   -73.887177  \n",
      "4    40.700348   -73.887177  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "filename = 'turnstile_weather_v2.csv'\n",
    "dataFrame = pandas.read_csv(filename)\n",
    "print dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Aggregate by morning(4, 8, 12H) and evening(16,20,0H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNIT' 'am_pm' 'weekday' 'rain' 'ENTRIESn_hourly' 'EXITSn_hourly'\n",
      " 'sub_hourly']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "#Create column 'Holiday'\n",
    "#dataFrame['Datetime'] = pandas.to_datetime(dataFrame['DATEn'],format='%Y-%m-%d')\n",
    "#dataFrame['Weekday'] = dataFrame['Datetime'].dt.dayofweek\n",
    "#dataFrame['Holiday'] = dataFrame['Weekday'].apply(lambda x: 'Weekday' if x < 5 else 'Holiday')\n",
    "\n",
    "dataFrame['am_pm'] = dataFrame['hour'].apply(lambda x: 'AM(4,8,12H)' if x == 4 | x == 8 | x == 12 else 'PM(16,20,0H)')\n",
    "\n",
    "dataFrame_gr = dataFrame.groupby(['UNIT','am_pm','weekday','rain'], as_index=False)\n",
    "dataFrame_gr = dataFrame_gr[[\"ENTRIESn_hourly\",'EXITSn_hourly']].sum() \n",
    "dataFrame_gr['sub_hourly'] = dataFrame_gr['ENTRIESn_hourly'] - dataFrame_gr['EXITSn_hourly']\n",
    "dataFrame_gr['UNIT'] = dataFrame_gr['UNIT'].replace('R','',regex=True).astype('float')\n",
    "\n",
    "\n",
    "print dataFrame_gr.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ggplot: (3821786)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ggplot import *\n",
    "pandas.options.mode.chained_assignment = None\n",
    "\n",
    "def plot_weather_data(turnstile_weather):\n",
    "    plot = ggplot(turnstile_weather, aes('UNIT','sub_hourly', fill='am_pm')) + \\\n",
    "    geom_point() \\\n",
    "    + xlim(0,464) + ylim(-400000,400000) \\\n",
    "    + ylab('Entry User Minus Exit User') + xlab('UNIT') + ggtitle('Variance of Entry vs Exit passengers by Station#')  \n",
    "    return plot\n",
    "\n",
    "plot_weather_data(dataFrame_gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. About the plot\n",
    "This plot shows how many people arrive/leave the station(UNIT) by the time of the day(AM and PM). Y axis indicates the difference between ENTRIESn_hourly and EXITSn_hourly. I assumed that more people arrive in the morning and leave in the evening between 0 to 150 UNIT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig3](fig6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Section 4. Conclusion\n",
    "Please address the following questions in detail. Your answers should be 1-2 paragraphs long.\n",
    "\n",
    "### 4.1 From your analysis and interpretation of the data, do more people ride the NYC subway when it is raining or when it is not raining?  \n",
    "A.\n",
    "\n",
    "Yes, more people ride the NYC subway when it is raining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 What analyses lead you to this conclusion? You should use results from both your statistical tests and your linear regression to support your analysis.\n",
    "A.\n",
    "\n",
    "Acording to the result of Question 1.3.\n",
    "\n",
    "- Mean of rainy day sample: 1105.44637675\n",
    "- Mean of non-rainy day sample: 1090.27878015\n",
    "- U-value: 1924409167.0\n",
    "- P-value: 0.0193096344138\n",
    "\n",
    "My confidence level is 95% and critical statistic value (α) is 0.05. P-value is 0.019 and \"P:0.019 < 0.025\" is true, so it's rejecting the null hypothesis. There is a significant difference between the means of the two samples. Mean of rainy day is greater than Mean of non-rainy day, I would say more people ride the subway in rainy day.\n",
    "\n",
    "Also, I compare the two R2 value with/without 'rain' parameters. The difference of two values is only 0.0027%. I don't think the number is significant, and it doesn't support the result of the statistical test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As follows, Comparing the two R2 value with/without 'rain' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import statsmodels.api as sm\n",
    "import operator as op\n",
    "\n",
    "def linear_regression(features, values):\n",
    "\n",
    "    features = sm.add_constant(features)\n",
    "    model = sm.OLS(values, features)\n",
    "    results = model.fit()\n",
    "    params = results.params\n",
    "    intercept = results.params[0]\n",
    "    params = results.params[1:]\n",
    "    \n",
    "    return intercept, params\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "\n",
    "    SST = ((data - np.mean(data))**2).sum()\n",
    "    SSReg = ((predictions - data)**2).sum()\n",
    "    r_squared = 1 - SSReg / SST\n",
    "    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without 'rain' parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: hour, weekday\n",
      "R2_value: 0.48136953934\n"
     ]
    }
   ],
   "source": [
    "def predictions(dataframe):\n",
    "    features = dataframe[['hour', 'weekday']]\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "\n",
    "    # Perform linear regression\n",
    "    intercept, params = linear_regression(features, values)\n",
    "    #print 'Intercept:' ,intercept\n",
    "    #print 'Parameters:'\n",
    "    #print params\n",
    "      \n",
    "    predictions = intercept + np.dot(features, params)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "mta_predictions = predictions(dataFrame)\n",
    "r2_value = compute_r_squared(dataFrame['ENTRIESn_hourly'], mta_predictions)\n",
    "print 'Parameters: hour, weekday'\n",
    "print 'R2_value:', r2_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With 'rain' parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: hour, weekday, rain\n",
      "R2_value: 0.481396426979\n",
      "R2 with rain - R2 without rain(%):  0.00268876390412\n"
     ]
    }
   ],
   "source": [
    "def predictions(dataframe):\n",
    "    features = dataframe[['hour', 'weekday','rain']]\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "\n",
    "    # Perform linear regression\n",
    "    intercept, params = linear_regression(features, values)\n",
    "    #print 'Intercept:' ,intercept\n",
    "    #print 'Parameters:'\n",
    "    #print params\n",
    "      \n",
    "    predictions = intercept + np.dot(features, params)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "mta_predictions = predictions(dataFrame)\n",
    "r2_value_rain = compute_r_squared(dataFrame['ENTRIESn_hourly'], mta_predictions)\n",
    "print 'Parameters: hour, weekday, rain'\n",
    "print 'R2_value:', r2_value_rain\n",
    "print 'R2 with rain - R2 without rain(%): ' , float(r2_value_rain)*100 - float(r2_value)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Reflection\n",
    "Please address the following questions in detail. Your answers should be 1-2 paragraphs long.\n",
    "\n",
    "### 5.1 Please discuss potential shortcomings of the methods of your analysis, including: Dataset, Analysis, such as the linear regression model or statistical test.\n",
    "A.\n",
    "\n",
    "First, there are not enough samples of rainy-days. Weekdays and holidays affect the number of riders. However, there are only 2 days of samples for holidays and rainy-days, against 9 days for holidays and non-rainy-days.\n",
    "\n",
    "Second, about the data visualization in question 3.1, the frequency should be devided by the days of rainy/non-rainy days to compare how rain affects the riders, or we could use an average of the frequency.\n",
    "\n",
    "Third, about the data visualization in question 3.2, which compare to Entry and Exit users at AM/PM. The circles are too busy in the plot and we can't see in detail in many station. Also, I think it's not easy to understand that what does the meaning of positive and negative values on x-axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 (Optional) Do you have any other insight about the dataset that you would like to share with us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- [ggplot](http://blog.yhathq.com/posts/ggplot-for-python.html)\n",
    "- [Normal Distributions](http://www2.nau.edu/mat114-c/ch2a.php)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import \"Improved data set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "filename = 'turnstile_weather_v2.csv'\n",
    "dataFrame = pandas.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Aggregate by hour, with morning(4, 8, 12H) and evening(16,20,0H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>am_pm</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R003</td>\n",
       "      <td>AM(4,8,12H)</td>\n",
       "      <td>16471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R003</td>\n",
       "      <td>PM(16,20,0H)</td>\n",
       "      <td>21001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R004</td>\n",
       "      <td>AM(4,8,12H)</td>\n",
       "      <td>42496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R004</td>\n",
       "      <td>PM(16,20,0H)</td>\n",
       "      <td>54507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R005</td>\n",
       "      <td>AM(4,8,12H)</td>\n",
       "      <td>51090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNIT         am_pm  ENTRIESn_hourly\n",
       "0  R003   AM(4,8,12H)            16471\n",
       "1  R003  PM(16,20,0H)            21001\n",
       "2  R004   AM(4,8,12H)            42496\n",
       "3  R004  PM(16,20,0H)            54507\n",
       "4  R005   AM(4,8,12H)            51090"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ggplot import *\n",
    "pandas.options.mode.chained_assignment = None\n",
    "\n",
    "dataFrame['am_pm'] = dataFrame['hour'].apply(lambda x: 'AM(4,8,12H)' if x == 4 | x == 8 | x == 12 else 'PM(16,20,0H)')\n",
    "dataFrame_ampm = dataFrame.groupby(['UNIT','am_pm'], as_index=False)\n",
    "dataFrame_ampm = dataFrame_ampm[[\"ENTRIESn_hourly\"]].sum()\n",
    "dataFrame_ampm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Number of Users by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_hour_data(turnstile_weather):\n",
    "    \n",
    "    plot = ggplot(turnstile_weather, aes('hour','ENTRIESn_hourly')) + \\\n",
    "    geom_point(alpha=0.1) + \\\n",
    "    xlim(-1, 21) + \\\n",
    "    ylim(0, 35000) + \\\n",
    "    ylab('Number of Users') + xlab('Hour') + ggtitle('Number of Users by Hour')\n",
    "\n",
    "    return plot\n",
    "\n",
    "print plot_hour_data(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4AM is the lowest\n",
    "- 8PM is the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](fig8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- AM(4,8,12H)\n",
      "count     7335.000000\n",
      "mean      3010.949693\n",
      "std       3168.521081\n",
      "min          0.000000\n",
      "25%       1036.000000\n",
      "50%       2205.000000\n",
      "75%       3894.000000\n",
      "max      32202.000000\n",
      "Name: ENTRIESn_hourly, dtype: float64\n",
      "\n",
      "- PM(16,20,0H)\n",
      "count    35314.000000\n",
      "mean      1653.051453\n",
      "std       2850.428103\n",
      "min          0.000000\n",
      "25%        213.000000\n",
      "50%        727.000000\n",
      "75%       1818.750000\n",
      "max      32814.000000\n",
      "Name: ENTRIESn_hourly, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print '- AM(4,8,12H)'\n",
    "datA =  dataFrame['ENTRIESn_hourly'][(dataFrame['am_pm']=='AM(4,8,12H)')]\n",
    "print datA.describe()\n",
    "print ''\n",
    "print '- PM(16,20,0H)'\n",
    "datB =  dataFrame['ENTRIESn_hourly'][(dataFrame['am_pm']=='PM(16,20,0H)')]\n",
    "print datB.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (91579459)>\n"
     ]
    }
   ],
   "source": [
    "def plot_freq_ampm_data(turnstile_weather):\n",
    "    \n",
    "    plot = ggplot(turnstile_weather, aes('ENTRIESn_hourly', fill='am_pm')) + \\\n",
    "    geom_histogram(binwidth=10000) + \\\n",
    "    xlim(0, 800000) + \\\n",
    "    ylab('Frequency') + xlab('Number of Hourly Users') + ggtitle('Frequency of the Hourly Users by time of the day')\n",
    "\n",
    "    return plot\n",
    "\n",
    "print plot_freq_ampm_data(dataFrame_ampm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean\n",
    "- AM(4,8,12H) : 3010.95<br>\n",
    "- PM(16,20,0H) : 1653.05\n",
    "\n",
    "##### Distribution\n",
    "- AM(4,8,12H) : Right skewed, centered around 50k, lower spread than PM data <br>\n",
    "- PM(16,20,0H) : Right skewed, centered between 50k and 150k, higher spread than AM data.\n",
    "\n",
    "##### Conclusion\n",
    "Consistant number of the users use the subway in the morning, on the other hand, there is a big peak at 8PM in the evening, and a larger number of users use the subway in a short time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](fig9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional notes: Gradient Descent (not part of answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UNIT', 'DATEn', 'TIMEn', 'ENTRIESn', 'EXITSn', 'ENTRIESn_hourly',\n",
       "       'EXITSn_hourly', 'datetime', 'hour', 'day_week', 'weekday',\n",
       "       'station', 'latitude', 'longitude', 'conds', 'fog', 'precipi',\n",
       "       'pressurei', 'rain', 'tempi', 'wspdi', 'meanprecipi',\n",
       "       'meanpressurei', 'meantempi', 'meanwspdi', 'weather_lat',\n",
       "       'weather_lon', 'am_pm'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "filename = 'turnstile_weather_v2.csv'\n",
    "dataFrame = pandas.read_csv(filename)\n",
    "\n",
    "def normalize_features(features):\n",
    "    ''' \n",
    "    Returns the means and standard deviations of the given features, along with a normalized feature\n",
    "    matrix.\n",
    "    ''' \n",
    "    means = np.mean(features, axis=0)\n",
    "    std_devs = np.std(features, axis=0)\n",
    "    normalized_features = (features - means) / std_devs\n",
    "    return means, std_devs, normalized_features\n",
    "\n",
    "def recover_params(means, std_devs, norm_intercept, norm_params):\n",
    "    ''' \n",
    "    Recovers the weights for a linear model given parameters that were fitted using\n",
    "    normalized features. Takes the means and standard deviations of the original\n",
    "    features, along with the intercept and parameters computed using the normalized\n",
    "    features, and returns the intercept and parameters that correspond to the original\n",
    "    features.\n",
    "    ''' \n",
    "    intercept = norm_intercept - np.sum(means * norm_params / std_devs)\n",
    "    params = norm_params / std_devs\n",
    "    return intercept, params\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "\n",
    "    SST = ((data - np.mean(data))**2).sum()\n",
    "    SSReg = ((predictions - data)**2).sum()\n",
    "    r_squared = 1 - SSReg / SST\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "def linear_regression(features, values):\n",
    "    \"\"\"\n",
    "    Perform linear regression given a data set with an arbitrary number of features.\n",
    "    \"\"\"\n",
    "    clf = SGDRegressor(n_iter=1000)\n",
    "    res = clf.fit(features, values)\n",
    "    intercept , params = res.intercept_, res.coef_\n",
    "    return intercept, params\n",
    "    '''\n",
    "    n_samples, n_features = 10, 5\n",
    "    np.random.seed(0)\n",
    "    y = np.random.randn(n_samples)\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    clf = SGDRegressor()\n",
    "    res = clf.fit(X, y)\n",
    "    print res.intercept_\n",
    "    print res.coef_\n",
    "    '''\n",
    "\n",
    "def predictions(dataframe, parameters):\n",
    "    '''\n",
    "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
    "    Using the information stored in the dataframe, let's predict the ridership of\n",
    "    the NYC subway using linear regression with gradient descent.\n",
    "    \n",
    "    '''\n",
    "    features = dataframe[parameters]\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='UNIT')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "    \n",
    "    # Get numpy arrays\n",
    "    features_array = features.values\n",
    "    values_array = values.values\n",
    "    \n",
    "    means, std_devs, normalized_features_array = normalize_features(features_array)\n",
    "\n",
    "    # Perform gradient descent\n",
    "    norm_intercept, norm_params = linear_regression(normalized_features_array, values_array)\n",
    "    intercept, params = recover_params(means, std_devs, norm_intercept, norm_params)\n",
    "    \n",
    "    predictions = intercept + np.dot(features_array, params)\n",
    "    # The following line would be equivalent:\n",
    "    # predictions = norm_intercept + np.dot(normalized_features_array, norm_params)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 value:  0.465921749309\n"
     ]
    }
   ],
   "source": [
    "parameters = ['hour','day_week', 'tempi','rain','precipi','wspdi','fog','pressurei']\n",
    "predi = predictions(dataFrame, parameters)\n",
    "r2_val = compute_r_squared(dataFrame['ENTRIESn_hourly'], predi)\n",
    "print 'R2 value: ', r2_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
